{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas: Using Python to read & explore tabular data \n",
    "\n",
    "Thursday October 6, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, we started to build on our introduction to Python by learning how to manipulate, clean, sort and analyze data in ordered lists. We also practiced working with a Python script for counting word frequencies in a text file, that we loaded in from our corpus. \n",
    "\n",
    "Often, though, the dataset that we want to work with, or explore take a slightly different form. We could read in a  SPREADSHEET as a plain text file, but that's not the most useful way to work with th\n",
    "\n",
    "Today we're going to learn how to use Python to read and explore tabular data. We'll learn some command for analyzing different kinds of values stored in tabular data (numeric and \"string\" data), practice a technique called exploratory data analysis, slice up our dataset into meaningful subsets, make simple data visualizations, and work with missing data.\n",
    "\n",
    "We're going to be working primarily with the Bellevue Almshouse Data. (For a refresher on where this data came from, check out [the project website](https://gih.hosting.nyu.edu/almshouse/the-almshouse-records/) and read the [accompanying essay by Annelise Shrout](https://crdh.rrchnm.org/essays/v01-10-(re)-humanizing-data/))\n",
    "\n",
    "\n",
    "We're also going to practice working with **YOUR** datasets!\n",
    "\n",
    "- [1. What is Pandas?](#1.-What-is-Pandas?)\n",
    "    - [Using Pandas to clean tabular data](#Using-Pandas-to-clean-tabular-data)\n",
    "    - [Cheatsheet: Operations we can peform on DataFrames](#Pandas-Cheat-Sheet)\n",
    "    - [Using Pandas to analyze data](#Using-Pandas-to-analyze-data)\n",
    "    - [**Exercise 1**: Finding out more about our dataset](#Exercise-1:-Finding-out-more-about-our-dataset) \n",
    "- [2: Make a simple data visualization](#2:-Make-a-simple-data-visualization) \n",
    "    - [**Exercise 2**: Your turn](#Exercise-2:-Your-turn!)\n",
    "- [**Exercise 3**: Working with your own dataset](#Exercise-3:-Working-with-your-own-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Pandas?\n",
    "\n",
    "We had a very quick preview of this last week. **`Pandas`** is a powerful Python library for working with tabular data. \n",
    "\n",
    "- `pandas` will read in tabular data––ie, a spreadsheet in the form of a .CSV, .TSV file. (Remember, CSV is short for comma-separarated values, a format for storing tabular data) This library can also work with data in slightly more complicated formats, like .JSON files.\n",
    "- `pandas` helps you explore, filter, and analyze data.\n",
    "\n",
    "\n",
    "When you read in a file, `pandas` creates a **DataFrame** -- this is a special Python datatype that we can perform perations on. Think of a a dataframe as a souped-up spreadsheet: it stores values in an \"array\" (a term for an arrangement of data in an ordered sequence that makes it easy to retrieve particular values,like all the values for the 5th row of a spreadsheet).\n",
    "\n",
    "\n",
    "![image](../_images/pusheen-computer.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, let's look back at the Bellevue Almshouse Dataset. We know that we can download this data in the form of a CSV file. What would we have to do to load in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import `pandas`\n",
    "Because `pandas` is an external library of scripts, we're going to have to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas library, nicknaming it \"pd\"\n",
    "import pandas as pd # Here the \"as pd\" gives it the nickname pd\n",
    "# Set the maximum number of rows to display\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our CSV\n",
    "Here, we're going to read in a CSV spreadsheet of bellevue_almshouse data using pandas (which we've nicknamed `pd`) and the `.read_csv()` operation and assign it to the variable `bellevue_df` (so we can remind ourselves that this is the bellevue dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load in our CSV file as a DataFrame and assign it to a variable called `bellevue_df`\n",
    "bellevue_df = pd.read_csv('../_datasets/bellevue-almshouse-dataset/bellevue_almshouse_modified.csv', delimiter=\",\", parse_dates=['date_in'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display our DataFrame\n",
    "Like other Python variables, we can simply type the name of our DataFrame to get a peek at what it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display just the first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas to read and sort tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate summary statistics of the DataFrame\n",
    "We can calculate some statistics on a DataFrame. This is a little like calculating summary statistics in Microsoft Excel or GoogleSheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns\n",
    "To select a column from the DataFrame, we will type the name of the DataFrame followed by square brackets `[]`and a column name in quotations marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the column labeled \"disease\"\n",
    "bellevue_df['disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple columns, we need to treat them like a dataframe, and enclose them in TWO sets of square brackets `[[ ]]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[['first_name', 'last_name', 'disease']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Values\n",
    "To count values, we select a column, and use the `.value_counts()` operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count only the top 10 \"diseases\", use brackets to slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas to clean tabular data\n",
    "\n",
    "### Rename columns\n",
    "\n",
    "Since so many of you brought this up in your homework, I thought we could try to rename some of the columns in our dataframe so that the variables better reflect the context.\n",
    "To rename columns in a dataframe, we use the `.rename()` method and the `columns=` parameter.\n",
    "\n",
    "Let's rename the \"disease\" column to \"disease_recorded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.rename(columns={'disease': 'disease_recorded'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this only temporarily changes the name of the variable. To permanently change it, we have to re-assign the variable `bellevue_df`, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df = bellevue_df.rename(columns={'disease': 'disease_recorded'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a peek inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Let's do the same thing for the \"profession,\" \"gender,\" and \"children\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df = bellevue_df.rename(columns={'profession': 'profession_recorded',\\\n",
    "                            'gender' : 'gender_recorded', 'children': 'children_recorded'})\n",
    "# Note: if a line of code gets too long and you want to make sure that you don't have to\n",
    "# scroll over to keep reading it, you can create a line break with a backslash \\\n",
    "# Jupyter will read the multiple lines as one continuous line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💡 Pro Tip 💡 \n",
    "> One of the handy things about working with data in `pandas` is that it allows you to manipulate data, replace missing values, add new columns, or drop columns --- all **without** touching the original CSV or text files that you're working with. This can be particularly handy for exploratory research and for making sure that you don't accidentally overwrite your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Transform data values\n",
    "Remember the string methods we learned last week ––how you can use `.str.replace()` or `str.lower()` to transform values in a string of text? Well, the same methods can be applied to pandas DataFrame columns!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, If we want to replace the gender columns’s single letter abbreviation for gender ('m'/'f') with “man” / “woman”, we could use the `.str.replace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[\"gender_recorded\"] = bellevue_df[\"gender_recorded\"].str.replace('m', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[\"gender_recorded\"] = bellevue_df[\"gender_recorded\"].str.replace('w', 'woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Cheat Sheet \n",
    "Open up the following [Pandas Cheat Sheet](python-pandas-cheat-sheet.md) in a new window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## `Pandas` Cheatsheet: Operations we can peform on DataFrames\n",
       "\n",
       "### Using string methods to clean or transform data in columns: \n",
       "\n",
       "![image](../_images/pusheen-yarn.png)\n",
       "\n",
       "| **Pandas String Method** | **Explanation**                                                                                   |\n",
       "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
       "| df['column_name']`.str.lower()`         | makes the string in each row lowercase                                                                                |\n",
       "| df['column_name']`.str.upper()`         | makes the string in each row uppercase                                                |\n",
       "| df['column_name']`.str.title()`         | makes the string in each row titlecase                                                |\n",
       "| df['column_name']`.str.replace('old string', 'new string')`      | replaces `old string` with `new string` for each row |\n",
       "| df['column_name']`.str.contains('some string')`      | tests whether string in each row contains \"some string\" |\n",
       "| df['column_name']`.str.split('delim')`          | returns a list of substrings separated by the given delimiter |\n",
       "| df['column_name']`.str.join(list)`         | opposite of split(), joins the elements in the given list together using the string                                                                   \n",
       "\n",
       "\n",
       "### Renaming, adding, dropping columns\n",
       "![image](../_images/pusheen-bake.png)\n",
       "\n",
       "| Pandas operation | Explanation |\n",
       "| :--- |:--- |\n",
       "|df`.rename(columns={'old_name_of_column': 'new_name_of_column'})` | rename a column (or columns)|\n",
       "|df`.add(columns='name_of_column')`| add a column |\n",
       "|df`.drop(columns='name_of_column')`| drop a column |\n",
       "\n",
       "### Working with missing data\n",
       "![image](../_images/pusheen-detective.jpg)\n",
       "\n",
       "| Pandas operation | Explanation |\n",
       "| :--- | :--- |\n",
       "| df['column_name']`.isna()` |returns a True/False pairs for each row in a dataframe that is blank|\n",
       "| df['column_name']`.notna()` |returns a True/False pairs for each row in a dataframe that is **NOT** blank|\n",
       "| df['column_name']`.fillna()` | will allow you to fill in blank values with a new value |\n",
       "\n",
       "### Sorting, calculating, and `groupby()`\n",
       "![image](../_images/pusheen-typing.png)\n",
       "\n",
       "Note: some of these operations will only be able to run on certain data types (like integers and floats), while others, like `.count()` can help you generate quantitative data about a column of qualitative values (like the number of times a value appears).\n",
       "\n",
       "| Pandas operation | Explanation |\n",
       "| :--- | :--- |\n",
       "|df['column_name']`.count()`| gives you the number of observations, ie the number of rows with non-blank values|\n",
       "|df['column_name']`.value_counts()` | aggregates the data in a column and counts (cumulatively) each unique value |\n",
       "|df['column_name']`.sum()` | gives you the sum of values|\n",
       "|df['column_name']`.mean()` | gives you the mean of values in the column\n",
       "|df['column_name']`.median()`| median of values|\n",
       "|df['column_name']`.min()` | gives the minimum value in the column |\n",
       "|df['column_name']`.max()` |gives the maximum value in the column|\n",
       "|df['column_name']`.mode()`| gives the mode of the column |\n",
       "|df['column_name'].`std()`| gives the \"unbiased standard deviation\" - a statistical term for the estimated dispersion of values| \n",
       "|df`.describe(include='all')` | calculates the summary statistics for all columns of the dataframe|\n",
       "|df`.groupby('column_name')` | allows us to group data and perform calculations on the groups.|\n",
       "\n",
       "> Note! Pay attention to the difference in syntax between `.describe()`, `.groupby()` and other commands.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(\"python-pandas-cheat-sheet.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas to analyze data\n",
    "\n",
    "### Counting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these commands we learned last week,when we used `.value_counts()` to look at the number of each value in the \"profession_recorded\" column and used the slice method (`[:10]`) to look at just the top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['profession_recorded'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting missing values\n",
    "\n",
    "The `.count()` method can also be applied to the DataFrame as a whole to count. Because `.count()` only counts a row with recorded data, we can combine it with the the `len()` function to get the percentage of each field with recorded data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the percentage of recorded data in each column of our dataframe\n",
    "bellevue_df.count() / len(bellevue_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and sorting values\n",
    "\n",
    "We can combine some of these operations we've learned.\n",
    "\n",
    "What if we wanted to look at all entries with a particular value? We can filter our dataframe for particular values in particular columns.\n",
    "\n",
    "We type the name of the DataFrame `bellevue_df` followed by square brackets `[]` and then, instead of inserting a column name in our brackets, we insert a True/False condition. For example, to select only rows that contain the value “carpenter,” we insert the condition `bellevue_df['profession'] == 'carpenter'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[bellevue_df['profession_recorded'] == \"carpenter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a variable with the name of our filter. For instance, if we wanted to find all professions of women, we could first create a filter for women, assign it to a variable, and then select the \"professions\" in our new subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter:\n",
    "bellevue_women = bellevue_df[bellevue_df['gender_recorded'] == 'woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, let's check the contents of our filter\n",
    "bellevue_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the \"profession_recorded\" column, and tally our results with  `.value_counts()\n",
    "bellevue_women['profession_recorded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to a CSV\n",
    "\n",
    "What if you want to save your output? There's a function for that! We can use the pands function `.to_csv` to write our output to a CSV file. \n",
    "\n",
    "Below, we’re also specifying that the encoding is utf-8 and that the Index (the bolded left-most column) is not included in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_women.to_csv(\"bellevue_women.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `groupby()` to generate statistics about your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.groupby()` is a useful function for performing more complicated computations on your dataframe. If you've ever used a **\"pivot table\"** in Excel or GoogleSpreadsheets, groupby() does something similar: it allows you to split your data into groups (eg all the results with particular values), apply a funciton, and then recombine them to from a new dataframe (For an example, see [the overview in the `pandas` user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)). We can group all the  so that you can group all the columns in the dataframe by the values in one column, or we group only a subset  of columns. \n",
    "\n",
    "- `.groupby('column_name')['name_of_selected_columns_to_be_grouped']` : will group only the selected columns\n",
    "\n",
    "Ack! What does this mean? Let's say we wanted to group the whole dataframe by recorded gender, and count how many of the fields were recorded for each, we would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.groupby('gender_recorded').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we wanted to know the median age of people, sorted by their recorded gender, we would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.groupby('gender_recorded')['age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Finding out more about our dataset \n",
    "\n",
    "In the field below, use what you've learned in the homework to complete the following sections: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, filter the dataframe to only include persons whose profession is \"teacher\"\n",
    "\n",
    "> ### !!! REMEMBER TO RUN THE CELLS ABOVE so you load in the CSV file and define variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the cell below, write the code that you would need to calculate the percentage of entries that contain no recorded data in the \"disease_recorded\" column? What is that percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Make a simple data visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make some simple visualizations of what we've found!\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded'].value_counts()[:10].plot(kind='bar', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\" Recorded ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used the `.plot()` function, and we used the parameter `kind=` to specify a bar chart. If we wanted to make it easier to read, we could flip the orientation to a horizontal chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded'].value_counts()[:10].plot(kind='barh', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\" Recorded ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could make it a pie chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded'].value_counts()[:10].plot(kind='pie', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\" Recorded ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ‼️ But wait --- what about all those ***blank spots*** that show up as NaN??\n",
    "\n",
    "Plotting functions in Python will ignore blank values. So all of those blank columns are ignored.\n",
    "\n",
    "We can try and make these blank spots a little more descriptive, much like we did for our simpler lists! \n",
    "\n",
    "\n",
    "### `.isna()` , `.notna()`, and `.fillna()`\n",
    "For dataframes, there are ways of sorting through missing data. These operations are called `.isna()` `.notna()` and `.fillna()`, which allow us to check if a value is NaN (or not), and to fill in blank values in a dataframe or in a section of a dataframe (like a column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column caled `disease_updated` that fills in all the blank spots in our `disease` column with \n",
    "# \"no disease recorded\"\n",
    "bellevue_df['disease_recorded_updated'] = bellevue_df['disease_recorded'].fillna('no disease recorded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's try and plot again, this time, plotting the column of updated diseases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded_updated'].value_counts()[:10].plot(kind='bar', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\"') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the plot above to our earlier plot. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Your turn!\n",
    "\n",
    "Let's try to explore another column of our dataset, professions. With a partner, try and outline the code you would have to write if you wanted to plot the top 10 professions:\n",
    "\n",
    "> Hint: Don't forget about missing data!\n",
    "\n",
    "> Are there persons in our dataset whose professions are not recorded? How might we capture that fact in our dataset and in our visualization?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Working with your own dataset\n",
    "\n",
    "Let's try some of what we've learned on a dataset of your choosing! In pairs, use the space below to load and examine your own dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, rename the variable `name_of_your_dataframe`. \n",
    "2. Then, place your cursor at the end of the file path `\"../_datasets/\"` and hit the `tab` button. You should see a list of files––I've uploaded versions of the datasets that you all were working on. \n",
    "3. Choose your dataset. Make sure that you choose a file ending in `.csv`. (Not all the files in the \"_datasets\" directory are CSV files).\n",
    "\n",
    "> ***Note***: if you're using the billboard_lyrics data, you need to specify the encoding as encoding=\"ISO-8859-1\"  \n",
    "> ***Note***: Some of you might not see your dataset here, or see a CSV version of your data––this may be because your dataset from you biography is not. If you do want to work with XML data, there are things we can do to create a dataframe from this, but we need to do a little more work. If you're up for a bit of a challenge, read through the https://pypi.org/project/pandas-read-xml/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_your_dataframe = pd.read_csv('../_datasets/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3a:\n",
    "\n",
    "Once you've loaded your dataset, use one of the methods we've learned to sort, select:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3b:\n",
    "Now, try and make a simiple data visualization using your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
